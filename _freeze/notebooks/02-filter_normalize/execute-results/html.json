{
  "hash": "6436e5407cf743d340c671573cb59c37",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Filter lowly expressed genes and TMM normalize\"\nauthor: Andreas Svendsen\n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(here)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nhere() starts at C:/Users/alosvendsen/OneDrive - Syddansk Universitet/PhD/Kurser/Biostat 2/biostat_project\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(limma)\nlibrary(edgeR)\nlibrary(data.table)\nlibrary(ggplot2)\n```\n:::\n\n\n### Filtering lowly expressed and duplicate genes\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Load data\ndge_data <- readRDS(\"outputs/data_processed/dge_data.rds\")\n```\n:::\n\n\n#### Filter lowly expressed genes\n\nMany possibilities. Use the filterByExpr funtion, or filter manually, as here:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nkeep <-\n  rowSums(cpm(dge_data) > 1) >= 2 # More than 1 CPM in at least 2 samples\n\ntable(keep)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nkeep\nFALSE  TRUE \n49098 13612 \n```\n\n\n:::\n:::\n\n\nSubset data by the logical vector\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Subset data by the logical vector\ndge_data_filtered <- dge_data[keep, keep.lib.sizes = FALSE]\n# keep.lib.sizes = FALSE, recomputes lib.sizes as number of rows changes.\n```\n:::\n\n\nFilter duplicates\n\nKeeping only the duplicated gene with the highest transcript! Get total number of reads of each gene in all samples, order decreasing order. Order them so the highest transcripted duplicate is kept.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncount_sums_ordered <-\n  order(rowSums(dge_data_filtered$counts), decreasing = TRUE)\n```\n:::\n\n\nThis object now contains an integer vector containing the indicies of each gene in descending order of the total numer og counts in all the samples.\n\nUse this vector to order the data in descending order based on number of counts\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndge_data_filtered <- dge_data_filtered[count_sums_ordered, ]\n```\n:::\n\n\nCheck for duplicate genes\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nduplicates <- duplicated(dge_data_filtered$genes$symbol)\nsum(duplicates) # Yields two duplicates.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2\n```\n\n\n:::\n:::\n\n\nView the duplicates\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nduplicates_symbols <- dge_data_filtered$genes[duplicates, \"symbol\"]\ndge_data_filtered$genes[dge_data_filtered$genes$symbol %in% duplicates_symbols, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          ENSEMBLE_ID   symbol                id_symbol\n62473 ENSG00000291072  CROCCP2  ENSG00000291072;CROCCP2\n23239 ENSG00000215908  CROCCP2  ENSG00000215908;CROCCP2\n35431 ENSG00000240356 RPL23AP7 ENSG00000240356;RPL23AP7\n62465 ENSG00000291064 RPL23AP7 ENSG00000291064;RPL23AP7\n```\n\n\n:::\n:::\n\n\nIf any duplicates remove them with:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndge_data_filtered <-\n  dge_data_filtered[!duplicates, , keep.lib.sizes = FALSE]\n```\n:::\n\n\n### TMM normalization\n\nThe normalization DOES NOT change the raw count values, but provides scaling factors that are used in subsequent analyses to adjust for library size and compositional differences.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndge_data_norm <- normLibSizes(dge_data_filtered, method = \"TMM\")\n```\n:::\n\n\nInspect normalisation factors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndge_data_norm$samples$norm.factors\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0.9784508 1.0028307 0.9865491 0.9878487 0.9016617 0.9046796 1.0010002\n [8] 1.0397491 1.0331277 1.0596380 0.9942724 0.9912140 1.0179186 1.0618761\n[15] 1.0235744 1.0318880\n```\n\n\n:::\n:::\n\n\n#### Visualize data after normalization\n\nCreate logCPM matrices with both normalized and non-normalized libraries. By default cpm() uses lib size norm factors if presenst in DGEList.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlogcpm_before <- cpm(dge_data_filtered, log = TRUE, prior.count = 2)\nhead(logcpm_before)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            S1       S2       S5       S6       S7       S8      S11      S12\n11069 16.47382 16.42465 16.45584 16.50192 15.08121 15.17085 16.21492 16.15015\n17851 14.64432 14.47638 14.51025 14.56301 14.29800 14.42634 14.65385 14.47892\n17336 13.54397 13.47746 13.57257 13.57304 15.28153 15.14676 13.76202 13.66599\n17900 13.84504 13.73219 13.78835 13.81237 13.63511 13.67906 13.88106 13.62050\n21399 13.90906 13.78777 13.92227 13.84408 13.68750 13.61888 13.77828 13.69885\n17810 13.72859 13.68942 13.65477 13.60761 13.39235 13.51075 13.66887 13.56601\n           S13      S14      S15      S16      S17      S18      S19      S20\n11069 15.56477 15.41336 16.16742 16.14900 15.39813 15.39794 16.42623 16.38937\n17851 14.72547 14.62170 14.56802 14.51735 15.20503 15.24215 14.48232 14.40512\n17336 14.21048 14.11383 13.35491 13.41233 12.79757 12.72375 13.42062 13.33509\n17900 14.09625 14.03945 13.76464 13.74038 14.39668 14.44148 13.77377 13.74587\n21399 13.78843 13.91913 13.66965 13.64738 14.67082 14.49331 13.56968 13.58071\n17810 13.83681 13.73694 13.53940 13.54934 14.34542 14.27177 13.56227 13.53703\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlogcpm_after <- cpm(dge_data_norm, log = TRUE, prior.count = 2)\nhead(logcpm_after)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            S1       S2       S5       S6       S7       S8      S11      S12\n11069 16.50525 16.42057 16.47538 16.51956 15.23055 15.31537 16.21348 16.09392\n17851 14.67575 14.47230 14.52979 14.58064 14.44734 14.57086 14.65241 14.42269\n17336 13.57540 13.47338 13.59210 13.59068 15.43087 15.29128 13.76058 13.60975\n17900 13.87647 13.72811 13.80788 13.83001 13.78445 13.82358 13.87961 13.56426\n21399 13.94049 13.78369 13.94181 13.86172 13.83684 13.76340 13.77683 13.64261\n17810 13.76002 13.68534 13.67431 13.62525 13.54170 13.65527 13.66743 13.50978\n           S13      S14      S15      S16      S17      S18      S19      S20\n11069 15.51775 15.32979 16.17571 16.16173 15.37251 15.31132 16.39261 16.34408\n17851 14.67845 14.53813 14.57631 14.53008 15.17940 15.15553 14.44871 14.35984\n17336 14.16346 14.03026 13.36320 13.42506 12.77194 12.63714 13.38701 13.28981\n17900 14.04924 13.95588 13.77292 13.75311 14.37106 14.35486 13.74015 13.70059\n21399 13.74142 13.83555 13.67794 13.66011 14.64519 14.40670 13.53607 13.53543\n17810 13.78980 13.65337 13.54768 13.56207 14.31980 14.18515 13.52865 13.49174\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Convert matrices to data.tables\ndt_before <- as.data.table(logcpm_before)\ndt_after <- as.data.table(logcpm_after)\n# Melt the data.tables and add a 'state' column\ndt_before <-\n  melt(dt_before,\n       measure.vars = colnames(logcpm_before),\n       variable.name = \"Sample\",\n       value.name = \"Log2_CPM\"\n  )\ndt_before[, state := \"Before Normalization\"]\n\ndt_after <-\n  melt(dt_after,\n       measure.vars = colnames(logcpm_after),\n       variable.name = \"Sample\",\n       value.name = \"Log2_CPM\"\n  )\ndt_after[, state := \"After Normalization\"]\n\n# Combine the two data.tables\ncombined_dt <- rbind(dt_before, dt_after)\n\n# Boxplots using ggplot2\np <- ggplot(combined_dt, aes(x = Sample, y = Log2_CPM)) +\n  geom_boxplot() +\n  labs(y = \"Log2 CPM\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  facet_wrap(\n    ~ factor(\n      combined_dt$state,\n      levels = c(\"Before Normalization\", \"After Normalization\")\n    ),\n    scales = \"free_y\"\n  )\n\np\n```\n\n::: {.cell-output-display}\n![](02-filter_normalize_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n### Save the filtered and normalized data\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# saveRDS(dge_data_norm, file = \"outputs/data_processed/dge_data_norm.rds\")\n```\n:::\n\n\n### Normalization\n\nNormalization is crucial to account for technical biases and ensure that the counts are comparable across samples. Factors like sequencing depth, RNA composition, and library preparation can introduce variations that are not related to the underlying biology. Normalizing the data corrects for these factors.\n\nThe TMM (Trimmed Mean of M-values) normalization method is a popular choice in the edgeR package for RNA-seq count data. It helps adjust for compositional differences between libraries (samples). In essence, TMM aims to make the count distributions as similar as possible across samples, so that differences in counts can be attributed to genuine differential expression rather than technical biases.\n\nRNA-seq data can be influenced by various factors, some of which are technical in nature. For example, differences in sequencing depth between samples can result in different total read counts. Another common issue is the presence of highly expressed genes that can dominate the total read count in a sample, thereby overshadowing other genes. The idea behind normalization is to adjust for these factors, so that the count data from different samples can be compared directly.\n\n#### What is TMM trying to address?\n\nWhen comparing two samples, if one gene is highly expressed in one sample compared to the other, it will \"consume\" a larger fraction of the total sequencing depth. This can create an illusion that other genes are downregulated in that sample, even if their absolute expression levels haven't changed. This phenomenon is known as the \"compositional difference.\"\n",
    "supporting": [
      "02-filter_normalize_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}